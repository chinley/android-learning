## 录音为WAV格式

录音是当前app最常具备的功能，本文通过以下部分介绍在android中如何实现录音：
- 基础音频知识
- android录音组件介绍
- 代码实现
- 注意的点
- 参考链接

### 基础音频知识
&emsp;**采样和采样频率：**现在是数字时代，在音频处理时要先把音频的模拟信号变成数字信号，这叫A/D转换。**要把音频的模拟信号变成数字信号，就需要采样，或者叫抽样**。当要把音频播放出来时则需要把数字信号转换成模拟信号，这叫D/A转换。一秒钟内采样的次数称为采样频率。根据Nyquist采样定理，要想重建原始信号，采样频率必须大于信号中最高频率的两倍。采样频率越高，越接近原始信号，但是也加大了运算处理的复杂度。人能感受到的频率范围为20HZ--20kHZ, 一般音乐的采样频率为**44.1kHZ**(根据Nyquist采样定理,采样频率大于信号中最高频率的两倍), 更高的可以是48kHZ和96kHZ，不过一般人用耳听感觉不出差别了。语音主要是以沟通为主，不需要像音乐那样清晰，分窄带和宽带。窄带频率范围为300Hz--3400Hz,相应的采样频率为8000Hz; 宽带频率范围为50Hz--7000Hz,相应的采样频率为16000Hz，用16k采样的语音就称为高清语音了。现在主流的语音采样频率为**16kHz**。

&emsp;**采样位数：**
数字信号是用0和1来表示的。采样位数就是采样值用多少位0和1来表示，也叫采样精度，用的位数越多就越接近真实声音。如用8位表示，采样值取值范围就是-128--127，如用16位表示，采样值取值范围就是-32768--32767。现在一般都用16位采样位数。

&emsp;**声道：**
通常语音只用一个声道。而对于音乐来说，既可以是单声道，也可以是双声道（即左声道右声道，叫立体声），还可以是多声道，叫环绕立体声，多用于影院中。

&emsp;**编解码：**
通常也把音频采样过程叫脉冲编码调制编码，即PCM（Pulse Code Modulation）编码，采样值也叫PCM值。为了节省保存空间或者发送流量，会对PCM值压缩。目前
主要有三大技术标准组织制定压缩标准：
a）ITU，主要制定有线语音的压缩标准（g系列），有g711/g722/g726/g729等。
b）3GPP,主要制定无线语音的压缩标准（amr系列等）, 有amr-nb/amr-wb。后来ITU吸纳了amr-wb，形成了g722.2。
c）MPEG,主要制定音乐的压缩标准，有11172-3，13818-3/7，14496-3等。
一些大公司或者组织也制定压缩标准，比如iLBC，OPUS。

无损压缩和有损压缩：把PCM数据压缩后无任何损伤叫无损压缩，不过压缩程度不高。把PCM数据压缩后有损伤叫有损压缩，最多可以压到几十分之一，不过音频质量差些。

&emsp;**码率:**
码率 = 采样频率 * 采样位数 * 声道个数； 例：采样频率44.1KHz，量化位数16bit，立体声(双声道)，未压缩时的码率 = 44.1KHz * 16 * 2 = 1411.2Kbps = 176.4KBps，即每秒要录制的资源大小,理论上码率和质量成正比

800 bps – 能够分辨的语音所需最低码率（需使用专用的FS-1015语音编解码器）
8 kbps —电话质量（使用语音编码）
8-500 kbps --Ogg Vorbis和MPEG1 Player1/2/3中使用的有损音频模式
500 kbps–1.4 Mbps —44.1KHz的无损音频，解码器为FLAC Audio,WavPack或Monkey's Audio
1411.2 - 2822.4 Kbps —脉冲编码调制(PCM)声音格式CD光碟的数字音频
5644.8 kbps —SACD使用的Direct Stream Digital格式


### android录音组件介绍

&emsp;**AudioRecord VS MediaRecorder**

&emsp;&emsp;AudioRecord在录制声音的过程可以获取音频数据，开发者可以通过这些数据来做一些视觉上的操作，录音完成后得到的是PCM数据，需要转码才能播放。

&emsp;&emsp;MediaRecorder经过了一系列的封装，除了录音之外还可以录制视频，录制完成可以通过自带的组件播放，但是开发者不能拿到数据。


&emsp;**AudioRecord的构造函数参数介绍**：

>AudioRecord(int audioSource, int sampleRateInHz, int channelConfig, int audioFormat, int bufferSizeInBytes)

- audioSource 这个参数指的是音频采集的输入源，接受的值定义在MediaRecorder.AudioSource里面，一般来说使用DEFAULT或者MIC即可。
- sampleRateInHz 指定采集音频的采样频率，比较通用的是44100(44.1kHz)，这个值是科学家们通过奈葵斯特采样定理得出的一个人能接受最佳的采样频率值。
- channelConfig 指定AudioRecord采集几个声道的声音，预设值定义在AudioFormat中，常用值有 CHANNEL_CONFIGURATION_MONO(单声道) 和 CHANNEL_CONFIGURATION_STEREO(双声道)。
- audioFormat 指定采样PCM数据的采样格式，预设值定义在也AudioFormat中，常用值有 ENCODING_PCM_8BIT、ENCODING_PCM_16BIT和ENCODING_PCM_FLOAT，值得强调的是ENCODING_PCM_16BIT可以保证兼容大部分Andorid手机。
- bufferSizeInBytes 配置AudioRecord内部的音频数据缓冲区，一般来说缓存区越小，产生的音频延迟也越小；值得注意的是，我们可以利用AudioRecord.getMinBufferSize()这个方法帮我们算出最小的缓存区大小，这个数值最好不要自己计算，毕竟不同厂商可能有不同的缓存区采集实现。

### 代码实现：

&emsp;**AudioRecord**：

&emsp;&emsp;AudioRecord录音过程：
- 创建AudioRecord
- 创建缓存区
- 开始录音
- 创建数据流一边将录音数据写入缓存区
- 写入完成后，文件头加入WAVE HEAD数据
- 从数据流中读取数据写入到文件中
- 关闭数据流
- 停止录音


```android

	//文件路径
    private String filePath;
    //文件夹路径
    private String FolderPath;

    //录音的线程
    private Thread mThread;
    private AudioRecord audioRecord;
    private boolean isRecording;
    private int channelConfiguration = AudioFormat.CHANNEL_IN_MONO;
    private int audioEncoding = AudioFormat.ENCODING_PCM_16BIT;
    private int sampleRate = 44100;
    private int bufferSizeInBytes;

    private final String TAG = "";
    public static final int MAX_LENGTH = 1000 * 60 * 10;// 最大录音时长1000*60*10;
    private double vol;
  public AudioRecoderUtils(){
        //默认保存路径为/sdcard/record/下
        FolderPath = Environment.getExternalStorageDirectory();
        File file = new File(FolderPath);
        if(!file.exists()){
            file.mkdirs();
        }
        bufferSizeInBytes = AudioRecord.getMinBufferSize(sampleRate,
                channelConfiguration, audioEncoding); // need to be larger than size of a frame

        audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC,
                sampleRate, channelConfiguration, audioEncoding,
                bufferSizeInBytes); //麦克风
    }

    public void startRecord(final String file_name){
        mThread = new Thread(new Runnable() {
            @Override
            public void run() {
                /* 获取开始时间 */
                startTime = System.currentTimeMillis();
                //设置录制指标
                isRecording = true;
                //设置存储路径
                filePath = FolderPath+"/"+file_name+".wav";
                File recordingFile = new File(filePath);
                OutputStream out = null;
                ByteArrayOutputStream baos = null;
                try {
                    baos = new ByteArrayOutputStream();
                    audioRecord.startRecording();
                    byte[] buffer = new byte[bufferSizeInBytes];
                    int bufferReadResult = 0;
                    while (isRecording) {
                        bufferReadResult = audioRecord.read(buffer, 0,
                                bufferSizeInBytes);
                        if(bufferReadResult>0){
                            baos.write(buffer, 0, bufferReadResult);
                            long v = 0;
                            for (int tmp : buffer)
                                v += tmp * tmp;
                            vol = 10 * Math.log10(v / (double) bufferReadResult); // 音量
                        }
                    }
                    buffer = baos.toByteArray();
                    out = new FileOutputStream(recordingFile);
                    out.write(getWavHeader(buffer.length));
                    out.write(buffer);
                } catch (FileNotFoundException e) {
                    e.printStackTrace();
                } catch (IOException e) {
                    e.printStackTrace();
                } finally {
                    if (out != null) {
                        try {
                            out.close();
                        } catch (IOException e) {
                            e.printStackTrace();
                        }
                    }
                    if(baos!=null){
                        try {
                            baos.close();
                        } catch (IOException e) {
                            e.printStackTrace();
                        }
                    }
                }
            }
        });
        mThread.start();
    }

    public void stopRecord(){
        stopRecording();
        filePath = "";
    }

    public byte[] getWavHeader(long totalAudioLen){
        int mChannels = 1;
        long totalDataLen = totalAudioLen + 36;
        long longSampleRate = sampleRate;
        long byteRate = sampleRate * 2 * mChannels;

        byte[] header = new byte[44];
        header[0] = 'R';  // RIFF/WAVE header
        header[1] = 'I';
        header[2] = 'F';
        header[3] = 'F';
        header[4] = (byte) (totalDataLen & 0xff);
        header[5] = (byte) ((totalDataLen >> 8) & 0xff);
        header[6] = (byte) ((totalDataLen >> 16) & 0xff);
        header[7] = (byte) ((totalDataLen >> 24) & 0xff);
        header[8] = 'W';
        header[9] = 'A';
        header[10] = 'V';
        header[11] = 'E';
        header[12] = 'f';  // 'fmt ' chunk
        header[13] = 'm';
        header[14] = 't';
        header[15] = ' ';
        header[16] = 16;  // 4 bytes: size of 'fmt ' chunk
        header[17] = 0;
        header[18] = 0;
        header[19] = 0;
        header[20] = 1;  // format = 1
        header[21] = 0;
        header[22] = (byte) mChannels;
        header[23] = 0;
        header[24] = (byte) (longSampleRate & 0xff);
        header[25] = (byte) ((longSampleRate >> 8) & 0xff);
        header[26] = (byte) ((longSampleRate >> 16) & 0xff);
        header[27] = (byte) ((longSampleRate >> 24) & 0xff);
        header[28] = (byte) (byteRate & 0xff);
        header[29] = (byte) ((byteRate >> 8) & 0xff);
        header[30] = (byte) ((byteRate >> 16) & 0xff);
        header[31] = (byte) ((byteRate >> 24) & 0xff);
        header[32] = (byte) (2 * mChannels);  // block align
        header[33] = 0;
        header[34] = 16;  // bits per sample
        header[35] = 0;
        header[36] = 'd';
        header[37] = 'a';
        header[38] = 't';
        header[39] = 'a';
        header[40] = (byte) (totalAudioLen & 0xff);
        header[41] = (byte) ((totalAudioLen >> 8) & 0xff);
        header[42] = (byte) ((totalAudioLen >> 16) & 0xff);
        header[43] = (byte) ((totalAudioLen >> 24) & 0xff);

        return header;
    }

    private long startTime;
    private long endTime;

    public void stopRecording() {
        try {
            isRecording = false;
            audioRecord.stop();
            audioRecord.release();
            audioRecord = null;
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

}
```

&emsp;**MediaRecorder**：

&emsp;&emsp;因为自己写的不是使用mediaRecorder录音，故可以看[这篇博客](https://www.jianshu.com/p/8d277561b6a0)
#### 注意的点
- **不使用录音功能后一定要释放**
- 录音功能的录音图标振幅，可以通过ImageView.getDrawable.setLevel方法实现。
- 申请权限：
>  <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />

>  <uses-permission android:name="android.permission.RECORD_AUDIO" />

#### 参考链接
- [https://www.jianshu.com/p/8d277561b6a0](https://www.jianshu.com/p/8d277561b6a0)
- [https://blog.csdn.net/fan7983377/article/details/51750583](https://blog.csdn.net/fan7983377/article/details/51750583)
- [https://www.cnblogs.com/renhui/p/7457321.html](https://www.cnblogs.com/renhui/p/7457321.html)